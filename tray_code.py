# -*- coding: utf-8 -*-
"""tray cnn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gYgLmL51shZ360c_asDfdHrvI2HFJjKP
"""

# Commented out IPython magic to ensure Python compatibility.
# %tensorflow_version 2.x

#install PyDrive
pip install PyDrive

import os
from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials

auth.authenticate_user()
gauth = GoogleAuth()
gauth.credentials = GoogleCredentials.get_application_default()
drive = GoogleDrive(gauth)

file_list = drive.ListFile({'q': "'root' in parents and trashed=false"}).GetList()
file_list[0]

download = drive.CreateFile({'id':'1ot_PmPOFYHwdxd-brePGhA1zIxhfvvPw'})
print("done")

download.GetContentFile('tray.zip')

!unzip tray.zip

from google.colab import drive
drive.mount('/content/drive')

!cp tray.zip drive/MyDrive/

!du -h drive/MyDrive/tray.zip

import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from tensorflow.keras.utils import to_categorical
from keras.preprocessing import image
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from tqdm import tqdm

train = pd.read_csv('/content/tray/traydetect.csv')

train_image = []
for i in tqdm(range(train.shape[0])):
    img = image.load_img('/content/tray'+train['images'][i], target_size=(224,224,3), grayscale=False)
    img = image.img_to_array(img)
    img = img/255
    train_image.append(img)
X = np.array(train_image)

print(X.shape)

y=train['id'].values
y=to_categorical(y)
print(y)
print(y.shape)

print(X.shape)
print(y.shape)

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)
print(type(X_test))

import keras
from keras.models import Sequential
from keras.layers import Dense, Activation, Dropout, Flatten,Conv2D, MaxPooling2D
from keras.layers import BatchNormalization
import numpy as np
np.random.seed(1000)
model = Sequential()

# 1st Convolutional Layer
model.add(Conv2D(filters=96, input_shape=(224,224,3), kernel_size=(11,11), strides=(4,4), padding='valid'))
model.add(Activation('relu'))
# Pooling 
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))
# Batch Normalisation before passing it to the next layer
model.add(BatchNormalization())

# 2nd Convolutional Layer
model.add(Conv2D(filters=256, kernel_size=(11,11), strides=(1,1), padding='valid'))
model.add(Activation('relu'))
# Pooling
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))
# Batch Normalisation
model.add(BatchNormalization())
#**special layer
#model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(2,2), padding='valid'))
#model.add(Activation('relu'))
# Pooling
#model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))
# Batch Normalisation
#model.add(BatchNormalization())


# 3rd Convolutional Layer
model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))
model.add(Activation('relu'))
# Batch Normalisation
model.add(BatchNormalization())

# 4th Convolutional Layer
model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='valid'))
model.add(Activation('relu'))
# Batch Normalisation
model.add(BatchNormalization())

# 5th Convolutional Layer
model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='valid'))
model.add(Activation('relu'))
# Pooling
model.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), padding='valid'))
# Batch Normalisation
model.add(BatchNormalization())

# Passing it to a dense layer
model.add(Flatten())
# 1st Dense Layer
model.add(Dense(2048, input_shape=(224*224*3,)))
model.add(Activation('relu'))
# Add Dropout to prevent overfitting
model.add(Dropout(0.4))
# Batch Normalisation
model.add(BatchNormalization())

# 2nd Dense Layer
model.add(Dense(1024))
model.add(Activation('relu'))
# Add Dropout
model.add(Dropout(0.4))
# Batch Normalisation
model.add(BatchNormalization())

# 3rd Dense Layer
model.add(Dense(512))
model.add(Activation('relu'))
# Add Dropout
model.add(Dropout(0.4))
# Batch Normalisation
model.add(BatchNormalization())

# Output Layer
model.add(Dense(2))
model.add(Activation('softmax'))
model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])

print(model.summary())

from keras import backend as K

def mcor(y_true, y_pred):
     #matthews_correlation
     y_pred_pos = K.round(K.clip(y_pred, 0, 1))
     y_pred_neg = 1 - y_pred_pos
 
 
     y_pos = K.round(K.clip(y_true, 0, 1))
     y_neg = 1 - y_pos
 
 
     tp = K.sum(y_pos * y_pred_pos)
     tn = K.sum(y_neg * y_pred_neg)
 
 
     fp = K.sum(y_neg * y_pred_pos)
     fn = K.sum(y_pos * y_pred_neg)
 
 
     numerator = (tp * tn - fp * fn)
     denominator = K.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
 
 
     return numerator / (denominator + K.epsilon())




def precision(y_true, y_pred):
    """Precision metric.

    Only computes a batch-wise average of precision.

    Computes the precision, a metric for multi-label classification of
    how many selected items are relevant.
    """
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
    precision = true_positives / (predicted_positives + K.epsilon())
    return precision

def recall(y_true, y_pred):
    """Recall metric.

    Only computes a batch-wise average of recall.

    Computes the recall, a metric for multi-label classification of
    how many relevant items are selected.
    """
    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
    recall = true_positives / (possible_positives + K.epsilon())
    return recall


def f1(y_true, y_pred):
    def recall(y_true, y_pred):
        """Recall metric.

        Only computes a batch-wise average of recall.

        Computes the recall, a metric for multi-label classification of
        how many relevant items are selected.
        """
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))
        recall = true_positives / (possible_positives + K.epsilon())
        return recall

    def precision(y_true, y_pred):
        """Precision metric.

        Only computes a batch-wise average of precision.

        Computes the precision, a metric for multi-label classification of
        how many selected items are relevant.
        """
        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))
        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))
        precision = true_positives / (predicted_positives + K.epsilon())
        return precision
    precision = precision(y_true, y_pred)
    recall = recall(y_true, y_pred)
    return 2*((precision*recall)/(precision+recall+K.epsilon()))

    
model.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy', precision ,recall,f1])

history=model.fit(X_train, y_train, epochs=3,batch_size=64,verbose=1)

acc      = history.history[     'accuracy' ]
#val_acc  = history.history[ 'val_accuracy' ]
loss     = history.history[    'loss' ]
#val_loss = history.history['val_loss' ]

epochs   = range(len(acc)) # Get number of epochs

#------------------------------------------------
# Plot training and validation accuracy per epoch
#------------------------------------------------
plt.plot  ( epochs,     acc )
#plt.plot  ( epochs, val_acc )
plt.xlabel('Number of Epoch')
plt.ylabel('Accuracy')
plt.title ('Validation accuracy')
plt.xticks([0, 4, 8, 12, 16, 20])
plt.figure()

#------------------------------------------------
# Plot training and validation loss per epoch
#------------------------------------------------
plt.plot  ( epochs,     loss )
plt.xlabel('Number of Epoch')
plt.ylabel('Training loss')
#plt.plot  ( epochs, val_loss )
plt.xticks([0, 4, 8, 12, 16, 20])
plt.title ('Validation loss'   )

model.save("tray.h5")

import cv2
test_image = []
im = cv2.imread('/content/tray/emptytray/IMG_0358.JPG')
img = image.load_img('/content/tray/emptytray/IMG_0358.JPG', target_size=(224,224,3), grayscale=False)
img = image.img_to_array(img)
img = img/255
test_image.append(img)
X_test = np.array(test_image)
test_image=[]
prediction = model.predict_classes(X_test)
k=prediction
prediction=to_categorical(prediction)
j=0

m=['Non-Empty','Empty']
for i in X_test:
   if k[j]==0:
      print(m[0])
   elif k[j]==1:
      print(m[1])

   
from google.colab.patches import cv2_imshow
dim=(250,250)

cv2_imshow(im)

import cv2
prediction = model.predict_classes(X_test)
k=prediction
print(prediction)
prediction=to_categorical(prediction)
j=0
m=['Empty','Non-Empty']
for i in X_test:
   if k[j]==0:
      print(m[0])
   elif k[j]==1:
      print(m[1])
 

   from google.colab.patches import cv2_imshow
   i=i*255
   i = cv2.cvtColor(i, cv2.COLOR_BGR2RGB)
   cv2_imshow(i)
   print("\n")
   j=j+1

from keras.models import load_model
score=model.evaluate(X_test,y_test)
print(score)

pred=model.predict(X,batch_size=None,verbose=0,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False)
pred=np.argmax(pred,axis=1)[:879]
label=np.argmax(y,axis=1)[:879]
print(pred)
print(label)

from sklearn.metrics import recall_score,precision_score,f1_score,confusion_matrix
recall=recall_score(label,pred,average='macro')
print("Recall")
print(recall)
precision=precision_score(label,pred,average='macro')
print("Precision")
print(precision)
f1=f1_score(label,pred,average='macro')
print("F1-Score")
print(f1)

import matplotlib.pyplot as plt
#Confusion Matrix
conf_matrix = confusion_matrix(y_true=label, y_pred=pred)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(12.5, 12.5))
ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')

plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()
